# Hybrid Cloud Quick Start

## ğŸš€ 5-Minute Setup

Get seamless **.diy + bolt.new sync**, **cloud backups**, and **multi-environment deployment**!

### 1. Start Your Local AI

Pick one:

```bash
# Option A: LM Studio
# Download from lmstudio.ai, start local server on port 1234

# Option B: Ollama
ollama serve  # Runs on port 11434
```

### 2. Start the Proxy Bridge

In your DLX Studios folder:

```bash
npm run hybrid
```

You'll see:
```
ğŸš€ DLX Studios Hybrid Bridge Server
âœ… Server ready!
```

### 3. Enable in UI

Go to **Settings â†’ Environment â†’ Hybrid Mode** and toggle ON.

## âœ… That's It!

Now you have:
- âš¡ Requests go to YOUR local models
- ğŸ’° Pay $0 for AI tokens
- ğŸ”’ Code stays on your machine
- â˜ï¸ Auto-fallback to cloud if local fails
- ğŸ”„ Automatic project synchronization
- ğŸ’¾ Cloud backup & restore
- ğŸš€ Multi-environment deployment

## ğŸ§ª Quick Test

### Test 1: Local Connection
```bash
curl http://localhost:8000/providers
```
Should show: "connected" âœ“

### Test 2: Sync Projects
1. Go to **Hybrid Mode Panel**
2. Click **Bi-Sync â‡„** button
3. Should show: "âœ“ Sync Complete!"

### Test 3: Discover Models
1. Go to **Settings â†’ Providers & Models**
2. Click lightning bolt **âš¡** icon
3. Should show: List of available models

## ğŸ”„ Daily Workflow

### Morning
```
1. Start LM Studio/Ollama
2. npm run hybrid
3. Open DLX Studios
4. Click Bi-Sync â‡„
5. Start working!
```

### Evening
```
1. Click Bi-Sync â‡„
2. Verify "Sync Complete!"
3. Close everything
```

## ğŸ’¡ How It Works

### Hybrid AI Routing
```
You type in bolt.new
      â†“
Proxy routes to localhost
      â†“
Your local AI responds
      â†“
Appears in bolt.new
```

### Project Synchronization
```
Local Changes â‡„ Cloud Storage
      â†“
Automatic Conflict Detection
      â†“
Smart Merge or Manual Resolution
      â†“
Always in Sync!
```

## ğŸ¯ Key Features

### Project Sync
- **Upload â†‘**: Push local changes to cloud
- **Download â†“**: Pull cloud changes to local
- **Bi-Sync â‡„**: Sync both directions automatically

### Cloud Backups
- Automatic snapshots before major operations
- One-click restore to any point in time
- Backup history with metadata

### Multi-Environment Deploy
- Local Development
- Development Server
- Staging
- Production

### Conflict Resolution
- Automatic detection
- Smart merging
- Manual resolution options

## ğŸ“– More Info

- **Complete Guide**: [HYBRID_CLOUD_INTEGRATION.md](./HYBRID_CLOUD_INTEGRATION.md)
- **Original Hybrid Mode**: [HYBRID_MODE.md](./HYBRID_MODE.md)
- **AI Features**: [AI_FEATURES.md](./AI_FEATURES.md)

## ğŸ†˜ Troubleshooting

**No providers detected?**
1. Is LM Studio/Ollama running?
2. Is the proxy server running?
3. Check: `curl http://localhost:1234/v1/models`

**CORS errors?**
- Make sure you're using the proxy URL
- Proxy server must be running

**Still stuck?**
- Check the full [Hybrid Mode Guide](./HYBRID_MODE.md)
- Review logs in proxy server terminal
